# ğŸ” Ollama Web Scraper


An intelligent **fullstack web scraping and parsing application** that combines **Selenium-based scraping**, **FastAPI + Chainlit backend**, and a **React + Tailwind frontend**.

The project integrates **Ollama** for AI-powered content extraction and supports **CI/CD deployment** with Fly.io and GitHub Pages.

* * * * *

# ğŸ¥ Video Demo

https://github.com/user-attachments/assets/e5bb8b18-dd37-47d6-96d1-0b3fc158b9dc

* * * * *

# âœ¨ Features


### Backend (FastAPI + Chainlit + Ollama)

-Â  Â ğŸ¤– **AI-Powered Extraction**: Extract structured information using natural language queries.

-Â  Â ğŸ”’ **Anti-Detection Scraping**: Stealth Selenium options, rotating user agents, and human-like patterns.

-Â  Â ğŸŒ **Multi-Method Scraping**: Requests + Selenium for maximum success rate.

-Â  Â ğŸ“Š **Chunk Processing**: Splits large DOMs into manageable pieces for AI parsing.

-Â  Â ğŸ¯ **Special Handling** for GitHub and popular sites.

-Â  Â ğŸ”„ **CORS Enabled**: Frontend-backend integration supported.

### Frontend (React + Tailwind)

-Â  Â âš¡ **Interactive UI**: Enter a URL to scrape, then parse results with natural language.

-Â  Â ğŸ–¼ï¸ **Responsive Design**: Built with Tailwind (CDN mode).

-Â  Â ğŸ”” **Success/Error Feedback**: Real-time status updates after scrape/parse.

-Â  Â ğŸŒ **Deployed on GitHub Pages** with CI/CD.

### DevOps

-Â  Â ğŸš€ **Backend Deployment**: Fly.io

-Â  Â ğŸŒ **Frontend Deployment**: GitHub Pages

-Â  Â ğŸ”„ **GitHub Actions CI/CD**: Automated build & deploy on push to `main`.

* * * * *

# ğŸ—ï¸ Project Structure
```bash
Ollama-Web-Scraper/

â”œâ”€â”€ backend/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # FastAPI + Chainlit backend

â”‚Â  Â â”œâ”€â”€ main.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â  # Entry point with routes + CORS

â”‚Â  Â â”œâ”€â”€ utils/

â”‚Â  Â â”‚Â  Â â”œâ”€â”€ web_scrape.pyÂ  Â  Â  Â  # Scraping logic (Selenium + requests)

â”‚Â  Â â”‚Â  Â â””â”€â”€ parse.pyÂ  Â  Â  Â  Â  Â  Â # AI parsing with Ollama

â”‚Â  Â â”œâ”€â”€ requirements.txtÂ  Â  Â  Â  Â # Backend dependencies

â”‚Â  Â â””â”€â”€ fly.tomlÂ  Â  Â  Â  Â  Â  Â  Â  Â # Fly.io config


â”œâ”€â”€ frontend/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # React + Vite frontend

â”‚Â  Â â”œâ”€â”€ index.html

â”‚Â  Â â”œâ”€â”€ src/

â”‚Â  Â â”‚Â  Â â”œâ”€â”€ App.jsxÂ  Â  Â  Â  Â  Â  Â  # UI (Scrape + Parse forms + results)

â”‚Â  Â â”‚Â  Â â””â”€â”€ main.jsx

â”‚Â  Â â”œâ”€â”€ package.json

â”‚Â  Â â””â”€â”€ vite.config.js

â”‚

â”œâ”€â”€ .github/workflows/CICD.ymlÂ  Â # GitHub Actions CI/CD

â”œâ”€â”€ README.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  # This file

```
* * * * *

# âš™ï¸ Installation

### Backend
```bash
git clone https://github.com/bassemalyyy/Ollama-Web-Scraper.git

cd Ollama-Web-Scraper/backend
```

### Create virtual environment
```bash
python -m venv myenv

myenv\Scripts\activateÂ  Â # Windows

source myenv/bin/activate # Linux/Mac
```

### Install dependencies
```bash
pip install -r requirements.txt
```

### Install Ollama + model
```bash
ollama pull llama3.2
```

### Run backend
```bash
chainlit run main.py
```

### Frontend
```bash
cd ../frontend
```

### Install dependenciess
```bash
npm install
```

### Run dev server
```bash
npm run dev
```
* * * * *

# ğŸš€ Deployment

-Â  Â **Backend** â†’ Fly.io (`flyctl deploy`)

-Â  Â **Frontend** â†’ GitHub Pages (`npm run deploy`)

Both are automated via **GitHub Actions** (`.github/workflows/CICD.yml`).

* * * * *

# ğŸ¯ Usage


1\.Â  Open the **frontend** (React app).

2\.Â  Enter a website URL â†’ press **Scrape**.

3\.Â  Enter a natural language query â†’ press **Parse**.

4\.Â  Results are displayed on the page.

### Example Workflow

-Â  Â **User**: Scrape `https://github.com/username`

-Â  Â **Backend**: âœ… Successfully scraped content.

-Â  Â **User**: Parse `repository names and descriptions`

-Â  Â **Bot**:
```bash
Â  Â   ğŸ¯ Results:

Â  Â  - awesome-project â†’ A cool Python project

Â  Â  - web-scraper â†’ AI-powered web scraping tool
```

* * * * *

# ğŸ“‹ Requirements

**Backend**
```bash
chainlit

fastapi

selenium

webdriver-manager

beautifulsoup4

langchain

langchain-ollama

requests
```

**Frontend**
```bash
react

vite

gh-pages
```
* * * * *

# ğŸ›¡ï¸ Anti-Detection Scraping

-Â  Â Rotating user agents

-Â  Â Stealth Selenium flags

-Â  Â Random delays for human-like browsing

-Â  Â JS execution control

-Â  Â Content quality detection (detects auth pages / bot blocks)

* * * * *

# ğŸ› Troubleshooting


-Â  Â **White page on GitHub Pages** â†’ Check `vite.config.js` â†’ set correct `base` path.

-Â  Â **No results from Parse** â†’ Enable debug mode in backend to see raw scraped content.

-Â  Â **Ollama errors** â†’ Ensure `ollama serve` is running.

-Â  Â **ChromeDriver issues** â†’ `webdriver-manager` auto-handles version, but ensure Chrome is installed.

* * * * *

# ğŸ™ Acknowledgments

-Â  Â **Chainlit** â†’ For interactive backend UI

-Â  Â **Ollama** â†’ Local LLMs

-Â  Â **Selenium + BeautifulSoup** â†’ Reliable scraping stack

-Â  Â **React + Vite + Tailwind** â†’ Frontend

-Â  Â **Fly.io & GitHub Actions** â†’ Smooth deployment

* * * * *

ğŸ”¥ Built with â¤ï¸ by **Bassem M. Aly**
